# 02_vae_embedding.ipynb

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, Model

# 데이터 로드
df = pd.read_parquet('data/antidepressant_timeseries.parquet')

# 시계열 벡터화 예시 (환자별 one-hot + 용량 스케일링)
# ... (중략) ...

# VAE 모델 정의
latent_dim = 10
input_dim = X_train.shape[1]

# 인코더
inputs = layers.Input(shape=(input_dim,))
h = layers.Dense(64, activation='relu')(inputs)
z_mean = layers.Dense(latent_dim)(h)
z_log_var = layers.Dense(latent_dim)(h)

def sampling(args):
    mean, log_var = args
    eps = tf.random.normal(shape=(tf.shape(mean)[0], latent_dim))
    return mean + tf.exp(0.5 * log_var) * eps

z = layers.Lambda(sampling)([z_mean, z_log_var])

# 디코더
decoder_h = layers.Dense(64, activation='relu')
decoder_out = layers.Dense(input_dim, activation='sigmoid')
h_decoded = decoder_h(z)
outputs = decoder_out(h_decoded)

# VAE 모델
vae = Model(inputs, outputs)
recon_loss = tf.reduce_mean(tf.keras.losses.mse(inputs, outputs)) * input_dim
kl_loss = -0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)
vae.add_loss(tf.reduce_mean(recon_loss + kl_loss))
vae.compile(optimizer='adam')

# 학습
vae.fit(X_train, epochs=50, batch_size=128, validation_split=0.1)

# 잠재 표현 저장
encoder = Model(inputs, z_mean)
Z_train = encoder.predict(X_train)
np.save('data/Z_train.npy', Z_train)
